\documentclass[output=paper]{langsci/langscibook}
\author{Petya Osenova\affiliation{Linguistic Modelling Department, IICT-BAS}%
\lastand Kiril Simov\affiliation{Linguistic Modelling Department, IICT-BAS}}
\title{Modeling Multiword Expressions in a parallel Bulgarian-English newsmedia corpus}\shorttitlerunninghead{Modeling Multiword Expressions in a parallel Bulgarian-English corpus}

\abstract{The paper focuses on the modeling of multiword expressions (MWE)
in Bulgarian--English parallel news corpora (SETimes; CSLI dataset and
PennTreebank dataset). Observations were made on alignments in which at
least one multiword expression was used per language. The multiword
expressions were classified with respect to the PARSEME lexicon based (WG1)
and Treebank-based (WG2) classifications. The non-MWE counterparts of MWEs
are also considered. Our approach is data-driven because the data of this
study was retrieved from parallel corpora and not from bilingual
dictionaries. The survey shows that the predominant translation relation
between Bulgarian and English is MWE-to-word, and that this relation does
not exclude other translation options. To formalize our observations, a
catenae-based modeling of the parallel pairs is proposed.}

\maketitle

\begin{document}

\section{Introduction}

This work proposes a catenae-based modeling of aligned pairs in parallel \linebreak
Bulgarian-English news corpora. A representation is  proposed, that  handles bilingual pairs
comprising at least one MWE. Our main aim is to offer a representation that
deals equally well with cross-language symmetries and asymmetries.

MWEs in each language were annotated independently from the alignments in
the corpus. Then, using the alignments, we examined how MWEs were translated
between the two languages. The following general alignment types of examples
are considered: MWE-to-MWE; MWE-to-Word; MWE-to-phrases. This general
typology is not exhaustive since, in most of the cases, another translation
option could have been used. Thus, it is interesting to observe the lexical
choices actually made in the parallel data.

In our work we refer to the classifications of MWEs developed within \linebreak
PARSEME
(PARSing and Multi-word Expressions)\footnote{PARSEME is an
interdisciplinary scientific network devoted to the role of multi-word
expressions in parsing ---  IC1207 COST Action.
\url{http://typo.uni-konstanz.de/parseme/}} in Working Groups 1 and 4 ---
{WG1: Lexicon-Grammar Interface} and {WG4: Annotating MWEs in Treebanks}.
The first one focuses on the linguistic properties of MWEs (structure,
reflexes to alternations such as passivisation, etc) and is more detailed,
while the second one is treebank-related and thus focuses on a different set
of MWE features such as the structural correspondences among MWEs across
languages and the distributions observed in corpora.

The results from the empirical study highlight at least the following
issues: (1) realization options of different MWE types in two languages with
different morphological complexity and word order; (2) a data-driven
typology of alignment possibilities among various types of MWEs; (3)
modeling the bilingual data with a catenae-based approach.

The paper is structured as follows: \sectref{RelatedWork} outlines the related
work; \sectref{Catenae} introduces catenae in a more formal way and also
describes the main operations over them;  \sectref{Sec:BCatenae} presents
bilingual catenae;  \sectref{TheData} describes the parallel data and its
classification;  \sectref{Sec:Conclusions} concludes the paper.




\section{Related Work}
\label{RelatedWork}

This section comprises two parts: a discussion on MWE classification and a
presentation of catenae. Concerning the former, there is extensive
literature as regards the study of MWEs in a language and across languages,
theoretical issues on MWE modelling, etc. Here only some of them are
mentioned. Concerning the latter, to our best knowledge, this is the first
attempt to use catenae for modelling bilingual or multilingual MWE
correspondences.

\subsection{MWE Classifications}

There is no widely accepted \isi{classification} of MWEs \citep{Kordoni2012}. For
the task of automatic recognition of MWEs in Bulgarian \cite{Stoyanova}
adopts the classification of \cite{baldwin2003} that could be characterized
as a semantically oriented division, since the MWEs are classified as
non-decomposable by meaning, idiosyncratically decomposable and simple
decomposable.

In \citet{Sag:2002} another classification is proposed. The MWEs are divided
into lexicalized phrases and institutionalized phrases. Here we do not
consider institutionalized phrases (being semantically and syntactically
compositional, but statistically idiosyncratic) as a distinct group.
Lexicalised phrases are further subdivided into fixed-expressions,
semi-fixed expressions and syntactically-flexible expressions. Fixed
expressions are said to be fully lexicalized and undergoing neither
morphosyntactic variation nor internal modification. Semi-fixed expressions
have a fixed word order, but “undergo some degree of lexical variation,
e.g. in the form of inflection, variation in reflexive form, and determiner
selection” \citet[4]{Sag:2002} (non-decomposable idioms, proper names).
Syntactically-flexible expressions allow for some variation in their word
order (light verb constructions, decomposable idioms).

On the multilinguality front, there are various approaches to different
MWE-related problems. For example, in \citet{RCZ14.331} the multilingual
annotation of light verb constructions is discussed for English, Spanish,
German and Hungarian. The specific annotation properties of these elements
in each language are described. Another popular task is the construction of
bi- or multilingual MWE lexicons on the base of parallel or comparable
corpora. In \citet{Hyeong-WonSeo} a context-oriented method is proposed for
French and Korean.

The WG4 classification was specially tailored to reflect the typology of
MWEs in syntactically annotated corpora (treebanks). It divides MWEs into
the following groups on the basis of the parts-of-speech (PoS) of the head
word:

\begin{enumerate}
\item Nominal MWEs
\item Verbal MWEs
\item Prepositional MWEs
\item Adjectival MWEs
\item MWEs of other categories
\item Proverbs
\end{enumerate}

Some of these groups are further subdivided into subtypes: {\em Nominal
MWEs} include named entities (NEs), nominal compounds as well as other
nominal MWEs; {\em Verbal MWEs} include: phrasal verbs, light verb
constructions, VP idioms and other verb MWEs. Thus, the WG4 classification
is syntax-based.

WP1 classification elaborates the typology by studying  idiomaticity and
flexibility on the basis of a large set of morphosyntactic diagnostics. With
respect to flexibility, the WG1 approach differs from \citet{Sag:2002} in
providing a coarser division between semi-flexible and flexible MWEs. With
respect to idiomaticity, the classification is based on
\citet{Baldwin2010}. It handles five types: lexical, syntactic, semantic,
pragmatic and statistical idiomaticity. Our work deals with syntactic and
semantic idiomaticity in a bilingual context.

\subsection{Catena}

The notion of catena\is{catenae} `chain' was introduced in \citet[284]{OGrady:98} as a
mechanism for representing the syntactic structure of idioms. He shows that
for this task there is need for a definition of syntactic patterns that do
not coincide with constituents. A variant of this definition was offered by \citet{Osborne2006}:
\begin{quotation}
The words A, B, and C (order irrelevant)
form a chain if and only if A immediately dominates B and C, or if and only
if A immediately dominates B and B immediately dominates C. \citep[258]{Osborne2006}
\end{quotation}

In recent years the notion of catena revived again and was applied to
dependency representations. Catenae have been used successfully for the
modelling of problematic language phenomena. \citet{Gross:2010:PACLIC2010}
presents the morphological and syntactic problems that have led to the
introduction of the subconstituent catena level. Constituency-based analysis
has to deal with non-constituent structures in ellipsis, idioms, verb
complexes.


Apart from the linguistic modelling of language phenomena, catenae have been
used in a number of NLP applications.
\citet{maxwell-oberlander-croft:2013:ACL2013}, for example, present an
approach to Information Retrieval based on catenae. The authors consider the
catena as a mechanism for semantic encoding which overcomes the problems of
long-distance paths and elliptical sentences. Also,
\citet{SANGUINETTI14.674} present a catena-related approach for syntactic
alignments in multilingual treebanks. In translation research, catenae are
best known as "treelets" \citep{journals/mt/QuirkM06}. We employ catenae,
that have already been used in NLP applications, to model the interface between the
treebank and the lexicon.

A first attempt to formalise MWE information with catenae is discussed in
\citet{simov-osenova:2015:Depling}. In the next section we present the main
notions of our proposal.


\section{Definition of Catena; Operations on Catenae}
\label{Catenae}


We follow the definition of catena\is{catenae} provided by \cite{OGrady:98} and
\citet{Gross:2010:PACLIC2010}: a \textsc{catena} is a word or a combination of
words directly connected with dominance relations. In fact, in the domain of
dependency trees, this definition is equivalent to a subtree definition.
Figure~\ref{fig:CatenaExamples} shows a complete dependency tree and some of
its catenae. Notice that the complete tree is also a catena. Individual
words are catenae, too. With ``root$_C$'' we mark the root of the catena
that might be identical with the root of the complete tree, but it also
might be different as are the cases of \textit{John} and \textit{an apple} in
Figure~\ref{fig:CatenaExamples}.


\begin{figure}[h]
  \centering
\begin{dependency}[theme = simple]
   \begin{deptext}[column sep=1em]
    John \& bought \& and \& ate \& an \& apple \\
   \end{deptext}
      \deproot[thick, edge unit distance=2ex]{2}{{\normalsize root}}
      \depedge[thick]{2}{1}{{\normalsize subj}}
      \depedge[thick, label style={below}]{2}{3}{{\normalsize cc}}
      \depedge[thick]{2}{4}{{\normalsize conj}}
      \depedge[thick]{2}{6}{{\normalsize iobj}}
      \depedge[thick]{6}{5}{{\normalsize det}}
   \end{dependency}

\begin{dependency}[theme = simple]
   \begin{deptext}[column sep=0.5em]
         John \\
   \end{deptext}
      \deproot[thick, edge unit distance=2ex]{1}{{\normalsize root$_C$}}
   \end{dependency}
\quad%
\begin{dependency}[theme = simple]
   \begin{deptext}[column sep=0.5em]
         bought \& and \& ate \\
   \end{deptext}
      \deproot[thick, edge unit distance=2ex]{1}{{\normalsize root$_C$}}
      \depedge[thick, label style={below}]{1}{2}{{\normalsize cc}}
      \depedge[thick]{1}{3}{{\normalsize conj}}
   \end{dependency}
\quad%
\begin{dependency}[theme = simple]
   \begin{deptext}[column sep=0.5em]
         an \& apple\\
   \end{deptext}
      \deproot[thick, edge unit distance=2ex]{2}{{\normalsize root$_C$}}
      \depedge[thick]{2}{1}{{\normalsize det}}
   \end{dependency}


  \caption{A complete dependency tree and some of its catenae.}
  \label{fig:CatenaExamples}
\end{figure}


A catena as an object on its own is a tree in which the nodes are decorated
with various labels including word forms, lemmas, and parts-of-speech; the
grammatical features and the arcs are augmented with dependency labels. The
labeling function is partial. Thus, some nodes or arcs remain
non-decorated in the catena and allow for different mappings to dependency
trees. When the catenae are not mapped on dependency trees, they are considered part of
the lexicon or the grammar of a given language.

We call the mapping of a catena onto a given dependency tree the \textsc{
realization of the catena in the tree}. We consider the realization of the
catena as a fully specified subtree including all the nodes and arc labels.
Each realization of a catena has to agree with its labeling outside of the
dependency tree. For example, the catena for \textit{(to) spill the beans} will
allow for any realization of the verb form like in: \textit{they spilled the
beans} and \textit{he spills the beans}. Thus, the catena in the lexicon will be
underspecified with respect to the grammatical features and word forms for
the corresponding lexical items.

\begin{figure}[h]
%
Lexical catena:
%
  \begin{center}
\begin{dependency}[theme = simple]
   \tikzstyle{wasp}=[draw=red, text = red, thick, solid]
   \tikzstyle{cooltext}=[draw=#1!60!black, thick, shade, top color=#1!60,
bottom color=white, rounded corners = 2pt]
   \begin{deptext}[column sep=0.8em]
         Vpi \& Pp \& Nc \\
      -- \&  |[cooltext=blue]|
\begin{otherlanguage*}{bulgarian}си\end{otherlanguage*} \&
|[cooltext=blue]|
\begin{otherlanguage*}{bulgarian}очите\end{otherlanguage*} \\
  |[cooltext=red]|
\begin{otherlanguage*}{bulgarian}затварям\end{otherlanguage*} \&
|[cooltext=red]| \begin{otherlanguage*}{bulgarian}си\end{otherlanguage*}
\&  |[cooltext=red]|
\begin{otherlanguage*}{bulgarian}око\end{otherlanguage*} \\
  |[cooltext=green]| shut \&  |[cooltext=green]| one's \&
|[cooltext=green]| eyes \\
   \end{deptext}
      \deproot[thick, edge unit distance=2ex]{1}{{\normalsize root}}
      \depedge[edge style={wasp}, label style={wasp}, label
style={below}]{1}{2}{{\normalsize clitic}}
      \depedge[edge style={wasp}, label style={wasp}]{1}{3}{{\normalsize
dobj}}
   \end{dependency}
  \end{center}
%
Realization 1:
%
  \begin{center}
\begin{dependency}[theme = simple]
   \tikzstyle{wasp}=[draw=red, text = red, thick, solid]
   \tikzstyle{cooltext}=[draw=#1!60!black, thick, shade, top color=#1!60,
bottom color=white, rounded corners = 2pt]
   \begin{deptext}[column sep=0.75em]
         Nc \& Pp \& Vpi \& R \& Nc \\
  |[cooltext=blue]|
\begin{otherlanguage*}{bulgarian}Очите\end{otherlanguage*} \&
|[cooltext=blue]|  \begin{otherlanguage*}{bulgarian}си\end{otherlanguage*}
\&  \begin{otherlanguage*}{bulgarian}затваряха\end{otherlanguage*}
\& \begin{otherlanguage*}{bulgarian}пред\end{otherlanguage*} \&
\begin{otherlanguage*}{bulgarian}фактите\end{otherlanguage*} \\
  |[cooltext=red]|
\begin{otherlanguage*}{bulgarian}око\end{otherlanguage*} \&
|[cooltext=red]|  \begin{otherlanguage*}{bulgarian}си\end{otherlanguage*}
\&  |[cooltext=red]|
\begin{otherlanguage*}{bulgarian}затварям\end{otherlanguage*} \&
\begin{otherlanguage*}{bulgarian}пред\end{otherlanguage*} \&
\begin{otherlanguage*}{bulgarian}факт\end{otherlanguage*} \\
  |[cooltext=green]| eyes \&  |[cooltext=green]| one's \&
|[cooltext=green]| shut \& |[cooltext=pink]| at \& |[cooltext=pink]| facts
\\
   \end{deptext}
      \deproot[thick, edge unit distance=2ex]{3}{{\normalsize root$_C$}}
      \depedge[edge style={wasp}, label style={wasp}, label
style={below}]{3}{2}{{\normalsize clitic}}
      \depedge[edge style={wasp}, label style={wasp}]{3}{1}{{\normalsize
dobj}}
      \depedge[thick]{3}{4}{{\normalsize iobj}}
      \depedge[thick]{4}{5}{{\normalsize pobj}}
   \end{dependency}
  \end{center}
%
Realization 2:
%
  \begin{center}
\begin{dependency}[theme = simple]
   \tikzstyle{wasp}=[draw=red, text = red, thick, solid]
   \tikzstyle{cooltext}=[draw=#1!60!black, thick, shade, top color=#1!60,
bottom color=white, rounded corners = 2pt]
   \begin{deptext}[column sep=0.75em]
         Np \& Pp \& Vpi \& Nc \\
      \begin{otherlanguage*}{bulgarian}Иван\end{otherlanguage*} \&
|[cooltext=blue]| \begin{otherlanguage*}{bulgarian}си\end{otherlanguage*}
\& \begin{otherlanguage*}{bulgarian}затваряше\end{otherlanguage*}
\& |[cooltext=blue]|
\begin{otherlanguage*}{bulgarian}очите\end{otherlanguage*} \\
      \begin{otherlanguage*}{bulgarian}Иван\end{otherlanguage*} \&
|[cooltext=red]|\begin{otherlanguage*}{bulgarian}си\end{otherlanguage*} \&
|[cooltext=red]|
\begin{otherlanguage*}{bulgarian}затварям\end{otherlanguage*} \&
|[cooltext=red]| \begin{otherlanguage*}{bulgarian}око\end{otherlanguage*}
\\
  |[cooltext=pink]| Ivan \&  |[cooltext=green]| one's \&  |[cooltext=green]|
shut \& |[cooltext=green]| eyes\\
   \end{deptext}
      \deproot[thick, edge unit distance=2ex]{3}{{\normalsize root}}
      \depedge[edge style={wasp}, label style={wasp}, label
style={below}]{3}{2}{{\normalsize clitic}}
      \depedge[thick]{3}{1}{{\normalsize subj}}
      \depedge[edge style={wasp}, label style={wasp}]{3}{4}{{\normalsize
dobj}}
\end{dependency}

  \caption{Catena realization.}
  \label{fig:CatenaRealization}
  \end{center}

\end{figure}


In this paper, the underspecified catena is called a \textsc{ lexicon catena (LC)}
 and it is stored in the lexical entries.
Figure~\ref{fig:CatenaRealization} shows a lexical catena for the idiom 
\begin{otherlanguage*}{bulgarian}затваря-м си
оч-и-те\end{otherlanguage*}, close-\textsc{PRS.1SG} \textsc{REFL} eye-\textsc{PL-DEF}, lit.
`shut one's eyes' and two of its realizations. Catenae in the lexicon do not
specify any particular word order\footnote{Formalisation of the word order
within the catena remains an open question for future work.}. The word order
of the catena realization reflects the rules of the grammar, therefore, the
realisation of the same catena in different dependency trees could
materialise with different word orders.

The upper part of the image in Figure~\ref{fig:CatenaRealization} represents
the lexicon catena for the idiom. It determines the fixed elements of the
catena: arcs and their labels and nodes and their labels. More precisely, the
following information is included: extended part of speech (PoS)\footnote{The
extended parts of speech are defined as prefixes of the tags in the
BulTreeBank tagset: \url{http://www.bultreebank.org/TechRep/BTB-TR03.pdf}}, word
forms, and lemmas\footnote{In some examples we give the important
information only, thus, some of these rows are missing. In some examples new
rows are used to introduce additional information.}. The translations of the
word form are presented, too. A dash (--) under a node indicates that the
corresponding element is not defined for the given node. In Figure 2, the dash
represents the fact that the word form for the verb node is
underspecified, therefore the idiom can be marked with a variety of tense,
person etc values.

In the two realizations, the fixed elements of the catena are represented as
in the lexicon catena. Thus, the lemmas are the same and the word forms, the
parts-of-speech and the grammatical features for the direct object and for
the clitic are also the same. The realizations are different from the lexicon
catenae with respect to the word forms and the grammatical features of the
verb node: in both examples the verb is in past tense while in the first
realization it is in plural and in the second in singular number. The word
order in the two realizations is different. Thus, the underspecified catenae
representation allows for various levels of morphosyntactic and semantic
flexibility within the multiword expressions.

\begin{figure}[h]
  \centering
\begin{dependency}[theme = simple]
   \tikzstyle{wasp}=[draw=red, text = red, thick, solid]
   \tikzstyle{cooltext}=[draw=#1!60!black, thick, shade, top color=#1!60,
bottom color=white, rounded corners = 2pt]
   \begin{deptext}[column sep=1em]
         I \& read \& -\\
   \& \& |[cooltext=yellow]| InfObj \\
   \end{deptext}
      \deproot[thick, edge unit distance=2ex]{2}{{\normalsize root$_C$}}
      \depedge[thick]{2}{1}{{\normalsize subj}}
      \depedge[thick]{2}{3}{{\normalsize dobj}}
   \end{dependency}
\quad%
\begin{dependency}[theme = simple]
   \tikzstyle{wasp}=[draw=red, text = red, thick, solid]
   \tikzstyle{cooltext}=[draw=#1!60!black, thick, shade, top color=#1!60,
bottom color=white, rounded corners = 2pt]
   \begin{deptext}[column sep=1em]
         a \& book\\
   \& |[cooltext=yellow]| InfObj \\
   \end{deptext}
      \deproot[thick, edge unit distance=2ex]{2}{{\normalsize root$_C$}}
      \depedge[thick]{2}{1}{{\normalsize det}}
   \end{dependency}


\begin{dependency}[theme = simple]
   \begin{deptext}[column sep=1em]
         I \& read \& a \& book\\
   \end{deptext}
      \deproot[thick, edge unit distance=2ex]{2}{{\normalsize root}}
      \depedge[thick]{2}{1}{{\normalsize subj}}
      \depedge[thick]{4}{3}{{\normalsize det}}
      \depedge[thick]{2}{4}{{\normalsize dobj}}
   \end{dependency}


  \caption{Composition of catenae.}
  \label{fig:Compisition}
\end{figure}

The catena representation of the lexical items explicitly denotes their
properties that constrain their interaction. We proceed to show how we model
the selectional restriction of a given lexical unit with respect to a catena
in a sentence. The main operation for modeling the interactions among the
catenae is called \textsc{composition}\is{catenae, composition}. For example, let us assume that the
verb \textit{to read} requires that its subject denotes a human and that its object
denotes an information object. In Figure~\ref{fig:Compisition} we present how
the catena for \textit{I read} is combined with the catena \textit{a book} in order to
form the catena \textit{I read a book}. The figure represents the level of word
forms and the level of semantics (specified only for the node, on which the
composition is performed). The catena for \textit{I read \ldots} specifies that the
unknown direct object has the semantics of an {\em Information Object}
(InfObj). The catena for \textit{a book} represents the fact that the book is an
Information Object. Thus the two catenae are composed on the two nodes
marked as InfObj. The result is represented at the lower part of Figure 3. We have
defined the composition operation for catenae that agree with each other on
one node; the operation can be defined on more agreeing nodes.

In Figure~\ref{fig:LexEntryByagamFT} the structure of the lexical entry for
the verb \begin{otherlanguage*}{bulgarian}бяга-м\end{otherlanguage*}, run-\textsc{PRS.SG}, `run' is presented in the sense `run away from facts'. The
verb selects an indirect object in the form of a prepositional phrase
introduced with the preposition
\begin{otherlanguage*}{bulgarian}от\end{otherlanguage*} `from'. In
Figure~\ref{fig:ZatvaryamSi} we give the catena for the synonymous MWE
\begin{otherlanguage*}{bulgarian}затварям си
очите\end{otherlanguage*}, close.\textsc{PRS.1SG} \textsc{REFL} \textsc{eye.PL}, `I close my
eyes'.


The lexical entry of a MWE uses the format: a \textbf{ lexicon-catena}, \textbf{
semantics} and \textbf{ valency}\footnote{The corresponding fields in the
lexical entry (rows in the tables below) are marked as: LC, SM, Fr (for
valency frames).}. Lexicon-catenae for the MWEs are stored in their
canonical form. The semantics part of a lexical entry is represented with a
logical formula comprising elementary predicates. The role of possible
modifiers has to be specified in the lexicon-catena, if modification of the
MWE is possible, for instance when structures with modifiers of
the noun can be attested in the data. For example, the MWE \begin{otherlanguage*}{bulgarian}затварям си
очите\end{otherlanguage*}, close.\textsc{PRS.1SG} \textsc{REFL} \textsc{eye.PL.DEF},  that is
synonymous to the verb
\begin{otherlanguage*}{bulgarian}бягам\end{otherlanguage*},
run.\textsc{PRS.1SG}, is presented in Figure~\ref{fig:ZatvaryamSi}\footnote{The
grammatical features are: `poss' for possessive pronoun, `plur' for plural
number and `def' for definite noun.}. The valency level is built as follows:
The root of the valency catena is marked with the identifier of the node in
the lexical catena for which the particular valency representation is
applicable. In Figure~\ref{fig:ZatvaryamSi} the valency representation is
applicable to the root node CNo1 of the lexical catena. The two catenae are
composed on this node. The composition is applied to the semantics of the
lexical catena and of the valency catena.  Notice that the nodes No1 and No2
are different from the nodes CNo1 and CNo2.

We use catenae to represent both single words and MWEs because single words
are also catenae by definition.


We can specify all the grammatical features of a lexical item using the
formal definition of catena given above. The semantics defined in the
lexical entry can be attached to each node in the lexicon-catena. In
Figure~\ref{fig:LexEntryByagamFT} there is just one node of the
lexicon-catena. In this document, we present only the set of elementary
predicates rather than providing their full semantic structures because we
focus on the principles of the representation \footnote{For  a full semantic
representation we employ Minimal Recursion Semantics, introduced by
\cite{copestake2005mrs}.}. In Fig.~\ref{fig:LexEntryByagamFT} the verb
introduces three elementary predicates: {\em run-away-from}($e$, $x_0$,
$x_1$), {\em fact}($x_1$), [1]($x_1$). The predicate {\em
run-away-from}($e$, $x_0$, $x_1$) represents the event and its main
participants: $x_0$, $x_1$. The predicate {\em fact}($x_1$) is part of the
meaning of the verb in the sense that the agent represented by $x_0$ will
run away from some fact. The underspecified predicate [1]($x_1$) has to be
compatible with the predicate {\em fact}($x_1$). This predicate is used for
incorporating the meaning of the indirect object \textit{at something} in the frame
\textit{shut one's eyes at something}. The valency frame is given as a set of
valency elements defined as a catena with a semantic description. The catena
describes the basic structure of the valency element including the necessary
lexical information, grammatical features, and the syntactic relation to the
main lexical item. The semantic description determines the main semantic
contribution of the frame element and is incorporated in the semantics of
the whole lexical item with structural sharing. In
Figure~\ref{fig:LexEntryByagamFT} there is only one frame element. It is
introduced with the preposition
\begin{otherlanguage*}{bulgarian}от\end{otherlanguage*} `from'. The
semantics originates in the dependent noun, that has to be compatible with
the predicate {\em fact}($x$) and in the underspecified predicate
[1]($x_1$), that may introduce a specific predicate. Via the structure
sharing index [1] this specific predicate is copied on the semantics of the
main lexical item.


The lexical entry in Figure 5 is similar to the one shown in
Figure~\ref{fig:LexEntryByagamFT}. The main differences are: the
lexicon-catena represents a MWE and not a single word. The semantics is the
same, because the verb and the MWE are synonyms. The valency frame contains
two alternative elements for indirect object introduced by two different
prepositions. The conclusion that the two descriptions are alternatives
follows from the fact that the verb has only an indirect object slot free. If
there was a direct object slot free as well then the valency set would
contain elements for it as well; however, in the MWE presented, the direct
object slot is occupied by a fixed element.

In a nutshell, catenae are an appropriate mechanism for representation of
MWEs because they adequately encode the grammatical flexibility of some
elements within the MWEs and also allow for the informative representation
of single words.


\twocolumn

\verb+   +

\begin{figure}[h]
\centering
\begin{tabular}{|p{0.6cm}|p{4.4cm}|}
\hline
LC &  \begin{dependency}[theme = simple]
   \tikzstyle{wasp}=[draw=red, text = red, thick, solid]
   \tikzstyle{cooltext}=[draw=#1!60!black, thick, shade, top color=#1!60,
bottom color=white, rounded corners = 2pt]
   \begin{deptext}[column sep=1em]
         Vpi \\
         -- \\
      |[cooltext=blue]| -- \\
  |[cooltext=red]|
\begin{otherlanguage*}{bulgarian}бягам\end{otherlanguage*} \\
  |[cooltext=green]| run \\
  CNo1 \\
   \end{deptext}
      \deproot[thick, edge unit distance=2ex]{1}{{\normalsize root$_C$}}

   \end{dependency}   \\ \hline
SM & CNo1: $\{$

run-away-from($e$,$x_0$,$x_1$),

fact($x_1$), [1]($x_1$) $\}$   \\ \hline
Fr & \begin{dependency}[theme = simple]
   \tikzstyle{wasp}=[draw=red, text = red, thick, solid]
   \tikzstyle{cooltext}=[draw=#1!60!black, thick, shade, top color=#1!60,
bottom color=white, rounded corners = 2pt]
   \begin{deptext}[column sep=1em]
         Vpi \& R \& N \\
         -- \& -- \& -- \\
      |[cooltext=blue]| -- \& |[cooltext=blue]|
\begin{otherlanguage*}{bulgarian}от\end{otherlanguage*} \&
|[cooltext=blue]| -- \\
  |[cooltext=red]|
\begin{otherlanguage*}{bulgarian}бягам\end{otherlanguage*} \&
|[cooltext=red]| \begin{otherlanguage*}{bulgarian}от\end{otherlanguage*}
\& |[cooltext=red]| -- \\
  |[cooltext=green]| run \& |[cooltext=green]| from \& |[cooltext=green]| --
\\
         CNo1 \& No1 \& No2 \\
   \end{deptext}
      \deproot[thick, edge unit distance=2ex]{1}{{\normalsize root$_C$}}
      \depedge[thick]{1}{2}{{\normalsize iobj}}
      \depedge[thick]{2}{3}{{\normalsize pobj}}
   \end{dependency} \\

  &
\textbf{ Semantics (SM):}
No2:

\{ fact($x$), [1] ($x$) \} \\ \hline

\end{tabular}

\caption{Lexical entry for the verb {\em run}.}
  \label{fig:LexEntryByagamFT}
\end{figure}

\verb+   +

\begin{figure}[h]
\centering
\begin{tabular}{|p{0.6cm}|p{4.8cm}|}
\hline
LC &  \begin{dependency}[theme = simple]
   \tikzstyle{wasp}=[draw=red, text = red, thick, solid]
   \tikzstyle{cooltext}=[draw=#1!60!black, thick, shade, top color=#1!60,
bottom color=white, rounded corners = 2pt]
   \begin{deptext}[column sep=1em]
         Vpi \& Pp \& Nc \\
         -- \& poss \& plur|def \\
      -- \&  |[cooltext=blue]|
\begin{otherlanguage*}{bulgarian}си\end{otherlanguage*} \&
|[cooltext=blue]|
\begin{otherlanguage*}{bulgarian}очите\end{otherlanguage*} \\
  |[cooltext=red]|
\begin{otherlanguage*}{bulgarian}затварям\end{otherlanguage*} \&
|[cooltext=red]| \begin{otherlanguage*}{bulgarian}си\end{otherlanguage*}
\&  |[cooltext=red]|
\begin{otherlanguage*}{bulgarian}око\end{otherlanguage*} \\
  |[cooltext=green]| shut \&  |[cooltext=green]| one's \&
|[cooltext=green]| eyes \\
         CNo1 \& CNo2 \& CNo3 \\
   \end{deptext}
      \deproot[thick, edge unit distance=2ex]{1}{{\normalsize root$_C$}}
      \depedge[edge style={wasp}, label style={wasp}, label
style={below}]{1}{2}{{\normalsize clitic}}
      \depedge[edge style={wasp}, label style={wasp}]{1}{3}{{\normalsize
dobj}}
\end{dependency}   \\ \hline
SM & CNo1: $\{$

run-away-from($e$,$x_0$,$x_1$),

fact($x_1$), [1]($x_1$) $\}$   \\ \hline
Fr & \begin{dependency}[theme = simple]
   \tikzstyle{wasp}=[draw=red, text = red, thick, solid]
   \tikzstyle{cooltext}=[draw=#1!60!black, thick, shade, top color=#1!60,
bottom color=white, rounded corners = 2pt]
   \begin{deptext}[column sep=1em]
         Vpi \& R \& N \\
         -- \& -- \& -- \\
      |[cooltext=blue]| -- \& |[cooltext=blue]|
\begin{otherlanguage*}{bulgarian}пред\end{otherlanguage*} \&
|[cooltext=blue]| -- \\
  |[cooltext=red]|
\begin{otherlanguage*}{bulgarian}затварям\end{otherlanguage*} \&
|[cooltext=red]|
\begin{otherlanguage*}{bulgarian}пред\end{otherlanguage*} \&
|[cooltext=red]| -- \\
  |[cooltext=green]| shut \&  |[cooltext=green]| at \&
 |[cooltext=green]| -- \\
         CNo1 \& No1 \& No2 \\
   \end{deptext}
      \deproot[thick, edge unit distance=2ex]{1}{{\normalsize root$_C$}}
      \depedge[thick]{1}{2}{{\normalsize iobj}}
      \depedge[thick]{2}{3}{{\normalsize pobj}}
   \end{dependency}

\textbf{ Semantics (SM):}

No2:  \{ fact($x$), [1] ($x$) \} \\ \hline

Fr & \begin{dependency}[theme = simple]
   \tikzstyle{wasp}=[draw=red, text = red, thick, solid]
   \tikzstyle{cooltext}=[draw=#1!60!black, thick, shade, top color=#1!60,
bottom color=white, rounded corners = 2pt]
   \begin{deptext}[column sep=1em]
         Vpi \& R \& N \\
         -- \& -- \& -- \\
      |[cooltext=blue]| -- \& |[cooltext=blue]|
\begin{otherlanguage*}{bulgarian}за\end{otherlanguage*} \&
|[cooltext=blue]| -- \\
  |[cooltext=red]|
\begin{otherlanguage*}{bulgarian}затварям\end{otherlanguage*} \&
|[cooltext=red]| \begin{otherlanguage*}{bulgarian}за\end{otherlanguage*}
\& |[cooltext=red]| -- \\
  |[cooltext=green]| shut \&  |[cooltext=green]| for \&
|[cooltext=green]| -- \\
         CNo1 \& No1 \& No2 \\
   \end{deptext}
      \deproot[thick, edge unit distance=2ex]{1}{{\normalsize root$_C$}}
      \depedge[thick]{1}{2}{{\normalsize iobj}}
      \depedge[thick]{2}{3}{{\normalsize pobj}}
   \end{dependency}

\textbf{ Semantics (SM):}

No2:  \{ fact($x$), [1] ($x$) \} \\ \hline

\end{tabular}
  \caption{Lexical entry for {\em I close my eyes}.}
  \label{fig:ZatvaryamSi}
\end{figure}


\onecolumn


In the rest of the paper we extend the above lexicon model in order to
handle correspondences among translation pairs with at least one MWE as a member.



\section{Bilingual catena modelling}
\label{Sec:BCatenae}
\is{catenae, bilingual modelling}

In this section we show the treatment of the following bilingual types of
pairs in Bulgarian and English: MWE-to-MWE and MWE-to-word. Our survey is
corpus-driven and we have chosen to discuss the most frequent pairs in our
data (see next section for data statistics).

\textbf{ MWE-to-MWE}

Let us consider the example:

\textbf{ Example RD\footnote{We use a special notation after each example: RD,
IG and CH for ensuring the correct connection with the corresponding
pictures in Figures
6, 7 and 8.}:} `reach a decision' 
\begin{otherlanguage*}{bulgarian}взема
решение\end{otherlanguage*}, take.\textsc{PRS.1SG} decision.


The two MWEs are flexible in several ways. First, the verb \textit{reach} (and
the corresponding one in Bulgarian взема `take, get' allow for
morphological variation -  tense, person, etc. The noun \textit{decision} allows
for pre- and post-modifiers as in: {\em we reached an important decision} or
{\em they will reach a decision about us tomorrow}. The Bulgarian MWE
presents the same behavior. Figure~\ref{fig:takedec} shows the lexical entry
for the parallel MWEs that are modeled as catenae. In the lexical entries we
can see the catenae for both MWEs. In the next row, the semantics of the
parallel MWEs is represented with a set of elementary predicates coupled
with a coindexation strategy between the semantics of the MWE and its
frames' semantics.

In Figure~\ref{fig:takedec}, the indices [1] and [2] represent the unknown
semantics of the modifying nouns. If no modification phrases exist, these
predicates are assumed to express the most general one, namely {\em
everything(x)}. Thus, the set $\{$take-\linebreak decision($e$,$x_0$,$x_1$),
decision($x_1$,$x_2$), [1]($x_1$), problem($x_2$), [2]($x_2$) $\}$
represents the \linebreak meaning of the  MWE\footnote{The examples present light verb
constructions that are translational equivalents bewteen Bulgarian and
English}: event ``take-decision'' $e$ with two participants $x_1$ and
$x_2$. The participant $x_0$ is the agent who takes the decision. The
participant $x_1$ is the main argument of the predicate for the relational
noun \textit{decision} that, being a two-argument predicate, introduces a third
participant in the event, namely the problem that the decision is about,
denoted with the variable $x_2$. If along with the lexicon catena the frame
catena is also realized in the sentence, then the new predicates introduced
by the corresponding nouns are added to the semantics of the new bigger
catena. This mechanism of representing bilingual lexicon entries is
suitable for the processing of the bilingual information including the
shared representation of the semantics and correspondences between the
grammatical features of the parallel realisations of the catenae in the
different languages.


\begin{figure}[h]
\centering
{\small
\begin{tabular}{|p{0.5cm}|p{5.2cm}|p{5.2cm}|}
\hline
LC &  \begin{dependency}[theme = simple]
   \tikzstyle{wasp}=[draw=red, text = red, thick, solid]
   \tikzstyle{cooltext}=[draw=#1!60!black, thick, shade, top color=#1!60,
bottom color=white, rounded corners = 2pt]
   \begin{deptext}[column sep=1em]
         V \& D \& N \\
         -- \& indef \& sg \\
    |[cooltext=blue]|  -- \& |[cooltext=blue]| -- \& |[cooltext=blue]|
decision \\
  |[cooltext=red]| reach \&  |[cooltext=red]| a \&  |[cooltext=red]|
decision \\
  |[cooltext=green]| reach  \&  |[cooltext=green]| a \&  |[cooltext=green]|
decision \\
         CNo1 \& CNo2 \& CNo3 \\
   \end{deptext}
      \deproot[thick, edge unit distance=2ex]{1}{{\normalsize root$_C$}}
      \depedge[edge style={wasp}, label style={wasp}, label
style={below}]{3}{2}{{\normalsize det}}
      \depedge[edge style={wasp}, label style={wasp}]{1}{3}{{\normalsize
dobj}}
\end{dependency} &  \begin{dependency}[theme = simple]
   \tikzstyle{wasp}=[draw=red, text = red, thick, solid]
   \tikzstyle{cooltext}=[draw=#1!60!black, thick, shade, top color=#1!60,
bottom color=white, rounded corners = 2pt]
   \begin{deptext}[column sep=1em]
         Vpi  \& Nc \\
         -- \&  sg|indef \\
   |[cooltext=blue]|   -- \&   |[cooltext=blue]|
\begin{otherlanguage*}{bulgarian}решение\end{otherlanguage*} \\
  |[cooltext=red]|
\begin{otherlanguage*}{bulgarian}взема\end{otherlanguage*} \&
|[cooltext=red]|
\begin{otherlanguage*}{bulgarian}решение\end{otherlanguage*} \\
  |[cooltext=green]| take \&  |[cooltext=green]| decision \\
         CNo1 \& CNo2 \\
   \end{deptext}
      \deproot[thick, edge unit distance=2ex]{1}{{\normalsize root$_C$}}
      \depedge[edge style={wasp}, label style={wasp}]{1}{2}{{\normalsize
dobj}}
\end{dependency}   \\ \hline
SM & CNo1: $\{$
%
take-decision($e$,$x_0$,$x_1$),

decision($x_1$,$x_2$), [1]($x_1$),

problem($x_2$), [2]($x_2$) $\}$ & CNo1: $\{$
%
take-decision($e$,$x_0$,$x_1$),

decision($x_1$,$x_2$), [1]($x_1$),

problem($x_2$),  [2]($x_2$)  $\}$  \\ \hline
Fr & \begin{dependency}[theme = simple]
   \tikzstyle{wasp}=[draw=red, text = red, thick, solid]
   \tikzstyle{cooltext}=[draw=#1!60!black, thick, shade, top color=#1!60,
bottom color=white, rounded corners = 2pt]
   \begin{deptext}[column sep=1em]
         A \& Nc \\
         -- \& -- \\
    |[cooltext=blue]|   -- \&  |[cooltext=blue]| decision \\
  |[cooltext=red]| -- \&  |[cooltext=red]| decision \\
  |[cooltext=green]| -- \& |[cooltext=green]| decision \\
         No1 \& CNo3 \\
   \end{deptext}
      \deproot[thick, edge unit distance=2ex]{2}{{\normalsize root$_C$}}
      \depedge[thick]{2}{1}{{\normalsize mod}}
\end{dependency}

\textbf{ SM:}
%
No1:  \{ [1] ($x$) \} &
\begin{dependency}[theme = simple]
   \tikzstyle{wasp}=[draw=red, text = red, thick, solid]
   \tikzstyle{cooltext}=[draw=#1!60!black, thick, shade, top color=#1!60,
bottom color=white, rounded corners = 2pt]
   \begin{deptext}[column sep=1em]
         A \& Nc \\
         indef \& sg|indef \\
    |[cooltext=blue]|   -- \&  |[cooltext=blue]|
\begin{otherlanguage*}{bulgarian}решение\end{otherlanguage*} \\
  |[cooltext=red]| -- \&  |[cooltext=red]|
\begin{otherlanguage*}{bulgarian}решение\end{otherlanguage*} \\
  |[cooltext=green]| -- \& |[cooltext=green]| decision \\
         No1 \& CNo3 \\
   \end{deptext}
      \deproot[thick, edge unit distance=2ex]{2}{{\normalsize root$_C$}}
      \depedge[thick]{2}{1}{{\normalsize mod}}
\end{dependency}

\textbf{ SM:}
%
No1:  \{ [1] ($x$) \} \\ \hline
Fr & \begin{dependency}[theme = simple]
   \tikzstyle{wasp}=[draw=red, text = red, thick, solid]
   \tikzstyle{cooltext}=[draw=#1!60!black, thick, shade, top color=#1!60,
bottom color=white, rounded corners = 2pt]
   \begin{deptext}[column sep=1em]
         Nc \& R \& Nc \\
         sg \& -- \& -- \\
    |[cooltext=blue]|  decision \& |[cooltext=blue]|  about \&
|[cooltext=blue]|  --  \\
  |[cooltext=red]| decision \& |[cooltext=red]| about \&
cooltext=red]|   -- \\
 |[cooltext=green]| decision \&  |[cooltext=green]| about \&
|[cooltext=green]| --  \\
         CNo1 \& No1 \& No2 \\
   \end{deptext}
      \deproot[thick, edge unit distance=2ex]{1}{{\normalsize root$_C$}}
      \depedge[thick]{1}{2}{{\normalsize mod}}
      \depedge[thick]{2}{3}{{\normalsize pobj}}
\end{dependency}

\textbf{ SM:}
%
No1:  \{ problem($x$), [2]($x$) \} & \begin{dependency}[theme = simple]
   \tikzstyle{wasp}=[draw=red, text = red, thick, solid]
   \tikzstyle{cooltext}=[draw=#1!60!black, thick, shade, top color=#1!60,
bottom color=white, rounded corners = 2pt]
   \begin{deptext}[column sep=1em]
         Nc \& R \& Nc \\
         -- \& -- \& -- \\
    |[cooltext=blue]|  -- \& |[cooltext=blue]|
\begin{otherlanguage*}{bulgarian}за\end{otherlanguage*} \&
|[cooltext=blue]|  --  \\
  |[cooltext=red]|
\begin{otherlanguage*}{bulgarian}решение\end{otherlanguage*} \&
|[cooltext=red]| \begin{otherlanguage*}{bulgarian}за\end{otherlanguage*}
\& |[cooltext=red]|   -- \\
 |[cooltext=green]| решение \&  |[cooltext=green]| за \&
|[cooltext=green]| --  \\
         CNo1 \& No1 \& No2 \\
   \end{deptext}
      \deproot[thick, edge unit distance=2ex]{1}{{\normalsize root$_C$}}
      \depedge[thick]{1}{2}{{\normalsize mod}}
      \depedge[thick]{2}{3}{{\normalsize pobj}}
\end{dependency}

\textbf{ SM:}
%
No2:  \{ problem($x$), [2]($x$) \} \\ \hline
\end{tabular}
}
\caption{Parallel Lexical Entries for the parallel MWEs: \textbf{ example RD}. }
  \label{fig:takedec}
\end{figure}


In some cases the lexical entry of the parallel MWEs might be quite simple,
as in the following example:

\textbf{ Example IG:} `in general',  \begin{otherlanguage*}{bulgarian}като
цяло\end{otherlanguage*}, as whole.


\begin{figure}[h]
\centering

\begin{tabular}{|p{0.6cm}|p{4.8cm}|p{4.8cm}|}
\hline
LC &  \begin{dependency}[theme = simple]
   \tikzstyle{wasp}=[draw=red, text = red, thick, solid]
   \tikzstyle{cooltext}=[draw=#1!60!black, thick, shade, top color=#1!60,
bottom color=white, rounded corners = 2pt]
   \begin{deptext}[column sep=1em]
         R \& A \\
         -- \& -- \\
    |[cooltext=blue]| in \&  |[cooltext=blue]| general \\
  |[cooltext=red]| in \&  |[cooltext=red]| general \\
  |[cooltext=green]| in  \&  |[cooltext=green]| general \\
         CNo1 \& CNo2  \\
   \end{deptext}
      \deproot[thick, edge unit distance=2ex]{1}{{\normalsize root$_C$}}
      \depedge[edge style={wasp}, label style={wasp}, label
style={wasp}]{1}{2}{{\normalsize pobj}}
\end{dependency}
&  \begin{dependency}[theme = simple]
   \tikzstyle{wasp}=[draw=red, text = red, thick, solid]
   \tikzstyle{cooltext}=[draw=#1!60!black, thick, shade, top color=#1!60,
bottom color=white, rounded corners = 2pt]
   \begin{deptext}[column sep=1em]
         R  \& Dm \\
         -- \&  -- \\
      |[cooltext=blue]|
\begin{otherlanguage*}{bulgarian}като\end{otherlanguage*} \&
|[cooltext=blue]|
\begin{otherlanguage*}{bulgarian}цяло\end{otherlanguage*} \\
  |[cooltext=red]|
\begin{otherlanguage*}{bulgarian}като\end{otherlanguage*} \&
|[cooltext=red]|
\begin{otherlanguage*}{bulgarian}цяло\end{otherlanguage*} \\
  |[cooltext=green]| as \&  |[cooltext=green]| whole \\
         CNo1 \& CNo2 \\
   \end{deptext}
      \deproot[thick, edge unit distance=2ex]{1}{{\normalsize root$_C$}}
      \depedge[edge style={wasp}, label style={wasp}]{1}{2}{{\normalsize
pobj}}
\end{dependency}  \\ \hline
SM & CNo1: $\{$ generally($e$,$e_1$) $\}$
& CNo1: $\{$ generally($e$,$e_1$) $\}$
  \\ \hline
Fr & & \\ \hline
\end{tabular}
\caption{Parallel Lexical Entries for the parallel MWEs: \textbf{ example IG}. }
  \label{fig:ingeneral}
\end{figure}

In Figure~\ref{fig:ingeneral} the adverbials share the same semantics. They do
not have frames and they allow for no modification. Only the PoS assigned to
their elements may be different.



\textbf{ MWE-to-word}

Concerning the relation MWE-to-word irrespectively of the language
direction,
two main cases can be observed. The first one relates to functional PoS,
such as the English preposition \textit{after} and the Bulgarian complementiser
\begin{otherlanguage*}{bulgarian}след като\end{otherlanguage*},
after when that are translational equivalents and have identical semantics
but differ in PoS and some selectional properties.

A challenging problem occurs when non-functional counterparts are
considered. For example, the term
\textbf{ Example CH:} the English term \textit{chemicals} translates into the Bulgarian MWE
\begin{otherlanguage*}{bulgarian}химическ-и
продукт-и\end{otherlanguage*}, chemical-\textsc{PL} product-\textsc{PL}.


Both expressions might be modified by adjectives, PPs or clauses:
\textit{dangerous chemicals}, \textit{chemicals from airplanes}, and \textit{chemicals that
are used by the pharmaceutical industry}. We find similar examples in
Bulgarian like \begin{otherlanguage*}{bulgarian}отровни химически
продукти\end{otherlanguage*}, poisonous.\textsc{PL} chemical.\textsc{PL} product.\textsc{PL}.

In Figure~\ref{fig:CH} a part of the parallel lexical entry for this example
is presented. It can be seen that in the English part of the lexical entry
there is a catena for a single word while in the Bulgarian part there is a
catena for a noun phrase of type adjectival modifier - head noun. The catena
for the Bulgarian MWE is underspecified for the word form and the
grammatical features because the whole phrase might be definite:
\begin{otherlanguage*}{bulgarian}химическите
продукти\end{otherlanguage*},`the chemicals'. The English
and the Bulgarian entries are specified for the same semantics. In the frame
part of the lexical entries all possible modifications have to be defined
(in the example just one of them is given, namely left modification with
adjectives; however, modification with PPs has been encountered in the data,
etc.). The important point here is that the lexicon catenae for the two
languages have to contain appropriate correspondences of the frames in order
to be proper translations of each other. The correspondences of the
frames have to be established on semantic grounds -  the corresponding
frames in the English and the Bulgarian part have to define the same
semantic contributions to the lexical catenae.

\begin{figure}[h]
\centering
{\small
%\bgroup
%\def\arraystretch{2}%  1 is the default, change whatever you need
%\def\tabularxcolumn#1{m{#1}}
\begin{tabular}{ | p{0.5cm}| p{5.5cm}| p{5.5cm}|}
\hline
LC & \begin{dependency}[theme = simple, x = 20mm, y = 10mm]
   \tikzstyle{wasp}=[draw=red, text = red, thick, solid]
   \tikzstyle{cooltext}=[draw=#1!60!black, thick, shade, top color=#1!60,
bottom color=white, rounded corners = 2pt]
   \begin{deptext}[column sep=1em]
         N \\
         pl \\
    |[cooltext=blue]|  chemicals \\
  |[cooltext=red]| chemicals \\
  |[cooltext=green]| chemicals \\
         CNo1 \\
   \end{deptext}
      \deproot[thick, edge unit distance=2ex]{1}{{\normalsize root$_C$}}
\end{dependency}  &  \begin{dependency}[theme = simple]
   \tikzstyle{wasp}=[draw=red, text = red, thick, solid]
   \tikzstyle{cooltext}=[draw=#1!60!black, thick, shade, top color=#1!60,
bottom color=white, rounded corners = 2pt]
   \begin{deptext}[column sep=1em]
         A  \& Nc \\
         -- \&  pl|indef \\
   |[cooltext=blue]|   -- \&   |[cooltext=blue]|
\begin{otherlanguage*}{bulgarian}продукти\end{otherlanguage*} \\
  |[cooltext=red]|
\begin{otherlanguage*}{bulgarian}химически\end{otherlanguage*} \&
|[cooltext=red]|
\begin{otherlanguage*}{bulgarian}продукт\end{otherlanguage*} \\
  |[cooltext=green]| chemical \&  |[cooltext=green]| products \\
         CNo1 \& CNo2 \\
   \end{deptext}
      \deproot[thick, edge unit distance=2ex]{2}{{\normalsize root$_C$}}
      \depedge[edge style={wasp}, label style={wasp}]{2}{1}{{\normalsize
mod}}
\end{dependency}  \\ \hline
SM & CNo1: $\{$ chemical-product($x_0$), [1]($x$) $\}$
& CNo2: $\{$ chemical-product($x_0$), [1]($x$) $\}$
  \\ \hline
Fr & \begin{dependency}[theme = simple]
   \tikzstyle{wasp}=[draw=red, text = red, thick, solid]
   \tikzstyle{cooltext}=[draw=#1!60!black, thick, shade, top color=#1!60,
bottom color=white, rounded corners = 2pt]
   \begin{deptext}[column sep=1em]
         A \& Nc \\
         -- \& -- \\
    |[cooltext=blue]| -- \&  |[cooltext=blue]| chemicals \\
  |[cooltext=red]| -- \&  |[cooltext=red]| chemicals \\
  |[cooltext=green]| -- \& |[cooltext=green]| chemicals \\
         No1 \& CNo1 \\
   \end{deptext}
      \deproot[thick, edge unit distance=2ex]{2}{{\normalsize root$_C$}}
      \depedge[thick]{2}{1}{{\normalsize mod}}
\end{dependency}

\textbf{ SM:} No1:  $\{$ [1]($x$) $\}$  & \begin{dependency}[theme = simple]
   \tikzstyle{wasp}=[draw=red, text = red, thick, solid]
   \tikzstyle{cooltext}=[draw=#1!60!black, thick, shade, top color=#1!60,
bottom color=white, rounded corners = 2pt]
   \begin{deptext}[column sep=1em]
         A \& Nc \\
         -- \& pl|indef \\
    |[cooltext=blue]|   -- \&  |[cooltext=blue]|
\begin{otherlanguage*}{bulgarian}продукти\end{otherlanguage*} \\
  |[cooltext=red]| -- \&  |[cooltext=red]|
\begin{otherlanguage*}{bulgarian}продукт\end{otherlanguage*} \\
  |[cooltext=green]| -- \& |[cooltext=green]| products \\
         No1 \& CNo2 \\
   \end{deptext}
      \deproot[thick, edge unit distance=2ex]{2}{{\normalsize root$_C$}}
      \depedge[thick]{2}{1}{{\normalsize mod}}
\end{dependency}

\textbf{ SM:} No1:  $\{$ [1]($x$) $\}$ \\ \hline
Fr  & \ldots

\textbf{ SM:} \ldots & \ldots

\textbf{ SM:} \ldots \\ \hline
\end{tabular}
%\egroup
}
\caption{Parallel Lexical Entries for the parallel MWEs: \textbf{ example CH}.}
  \label{fig:CH}
\end{figure}

The frame catena in Figure~\ref{fig:CH} marks the fact that the lexical catena
can be modified by an adjectival modifier. The realization of such a modifier is additional to the realization of the adjectival modifier 
\begin{otherlanguage*}{bulgarian}химическ-и\end{otherlanguage*}, chemical-\textsc{PL}
that is a fixed part of the MWE. In the frame catena we mark only the nominal head of the MWE.

Note that we do not aim at an exhaustive analysis of all the bilingual
pairs. Our aim is to present a mechanism which would deal with both -
symmetric (MWE-to-MWE) and asymmetric (MWE-to-Word) relations in
translations. Our hypothesis is that the correspondences between the two
languages in the lexicon have to be governed by the semantics of the lexical
catenae and the semantic contribution of the possible frames. A consequence
of this hypothesis is that in the lexicon we have to allow for correspondences
not only between MWEs, but also between MWEs and words, and between
words/MWEs in one of the languages and compositional phrases in the other.

\section{Classification of the parallel data}
\label{TheData}


In this section we provide a classification of parallel pairs that consist
of two MWEs or a MWE and a word. For each class of correspondences the
minimum information to be included in the lexical entries has been
specified.
The parallel Bulgarian-English newsmedia corpus consists of two parts: SETimes plus CSLI
dataset (920 sentences, or 9308 tokens); PenTreebank dataset (838 sentences,
or 21949 tokens). Thus, our final dataset consists of: 1758 sentences or 31
257 tokens.

The data was aligned according to \cite{Simov2011}. However, the
alignments did not mark the MWEs. For that reason, additional annotation was
performed for detecting the alignments with MWEs in at least one of the two
languages.

\begin{table}[ht]
\centering
\begin{tabular}{p{3.0cm}p{3.0cm}}
\lsptoprule
%\hline
& \textbf{Occurrences}\\
\midrule
MWE-to-MWE & 126 \\%\hline
MWE-to-Word & 370 \\%\hline
MWE-to-Phrase & 14 \\\hline
%\hline
% &  & \hline
Total & 370 \\%\hline
% &  & \hline
\lspbottomrule
\end{tabular}
 \caption{General Classification.}
\end{table}


Our aim was to extract various types of alignments with at least one
MWE as a member. Thus, our data included the following general types:
MWE-to-word; MWE-to-MWE and MWE-to-compositional phrase in both language directions.



\begin{table}[ht]
\centering
\begin{tabular}{p{3.0cm}p{3.0cm}}
\lsptoprule
%\hline
& \textbf{MWE-to-Word }\\
\midrule
Bulgarian MWE & 220 \\
English MWE & 150 \\\hline
%\hline
% &  & \hline
Total & 370 \\%\hline
% &  & \hline
\lspbottomrule
\end{tabular}
 \caption{MWE-to-Word classification.}
\end{table}


As shown in Table 1, 510 occurrences of MWEs were detected within these
data. Of them, 370 MWEs are of type MWE-to-Word (for example the English
\textit{within} is translated as \begin{otherlanguage*}{bulgarian}в
рамките на\end{otherlanguage*}, in frame.\textsc{PL} of, within the
framework of; 126 MWEs are of type MWE-to-MWE (for example the English
\textit{with respect to} is translated as \begin{otherlanguage*}{bulgarian}що
се отнася до\end{otherlanguage*}, as far as relate.\textsc{PRS.3SG} to,
and 14 MWEs are of type MWE-to-phrase (for example, the English
\textit{take-it-or-leave it} is translated as
\begin{otherlanguage*}{bulgarian}приемаш или се
отказваш\end{otherlanguage*}, accept.\textsc{PRS.2SG} or refuse.\textsc{PRS.2SG} ).

Table 2 shows the distribution of MWEs in the largest set, namely the set of
the type MWE-to-Word: 220 Bulgarian and 150 English MWEs were detected.

%\section{Bilingual Classifications of Multiword Expressions}
%\label{PARSEMEClassifications}

Two types of classification are applied. First,  
the aligned pairs are classified into three groups: MWE-to-MWE, MWE-to-Word and
MWE-to-Phrase (see Table 1 and Table 2). This classification offers a coarse picture of the bilingual
situation. Then, the classification methods developed in PARSEME WG1 and WG4 are applied. These classifications draw on the structural and
the semantic features of MWEs.

When mapped to the PARSEME WG1/WG4 typologies, both languages showed very similar MWE properties. Thus, the most frequent MWE types in both languages
are: {\em Verbal MWEs}; {\em Noun MWEs}; {\em Other categories of MWEs}.
The language specific features are evident in the subtypes. Thus, 
phrasal verbs and reflexive (formally or semantically) se-verbs seem to
be the most frequently used verb MWEs in the English and Bulgarian data
respectively. Both languages feature light verb constructions and VP idioms.
Lastly, compounds are the most frequent type of noun MWEs in English and adjective-noun phrases in Bulgarian. 

To present a slightly more detailed analysis of the correspondence type
MWE-to-MWE, we use the WG1 classification (predominantly the syntactic and
semantic dimensions), that focuses on the internal structure of the MWEs.


Within the set of the {\em MWE-to-MWE pairs}, correspondences are grouped to straightforward mappings and to cross-language specific types. A presentation of these two groups follows. 
%\begin{itemize}
%\item

\subsection{ Straightforward mappings}

This class includes: Verb MWEs (light verb constructions, VP idioms); Other
categories (adverbs, prepositions), etc.


In this group of \isi{translational equivalents}, two main classes of Bulgarian- \linebreak English MWE pairs are identified:  pairs with cross-lingual
variance that has to be considered in the lexicons, and MWEs with
no cross-lingual variance that is trivially handled in the lexicon. In the first case the grammatical behaviour of the MWE elements in both languages has to
be taken into account, such as the possibility of inflection for number, or of accepting modifiers. In the second case the MWE elements hardly undergo inflection 
or modification, so the translational equivalents are registered in the lexicon without further elaboration on the behaviour of their elements.
 
The first case includes verb and noun MWEs and the second one complex PoS and
non-inflecting MWEs. 

Examples for the first group are given below:

\begin{itemize}
\item Light verbs in one language often correspond to similar constructions
in the other. For instance,

\verb+ + `reach a decision', \begin{otherlanguage*}{bulgarian}взем-а
решение\end{otherlanguage*}, take-\textsc{PRS.1SG} decision\\ where V NP
in English translates to V NP in Bulgarian

\verb+ + `take effect',  \begin{otherlanguage*}{bulgarian}влез-е в
сила\end{otherlanguage*}, enter-\textsc{PRS.3SG} in power 

\verb+ + `take control', \begin{otherlanguage*}{bulgarian}влез-е във
владение\end{otherlanguage*}, enter-\textsc{PRS.3SG}  in possession\\
where V NP translates to V PP.

In this group the MWEs are assigned identical semantics, but they might
differ in the elements and in valence selection.

\item Noun MWEs of the type A N that are translational equivalents,
often are literal translations of each other:

\verb+ + `tough line', \begin{otherlanguage*}{bulgarian}твърда
позиция\end{otherlanguage*}, tough position

\verb+ +`free market', \begin{otherlanguage*}{bulgarian}свободни-я
пазар\end{otherlanguage*}, free-\textsc{DEF} market

\verb+ + `real estate',
\begin{otherlanguage*}{bulgarian}недвижимо-то
имущество\end{otherlanguage*}, nonmoving-\textsc{DEF} estate'

The MWEs in this group share the same semantics and the same modification
mechanisms.

\item The structure V NP tends to characterise both the members in pairs consisting of verb
MWE translational equivalents:

\verb+ + `is drawing fire',
\begin{otherlanguage*}{bulgarian}привлич-а
критик-и-те\end{otherlanguage*}, attract-\textsc{PRS.3SG} critic-\textsc{PL-DEF}.

\verb+ + `haven't got a clue', \begin{otherlanguage*}{bulgarian}нямат
представа\end{otherlanguage*}, not.have.\textsc{PRS.3PL} idea

The MWEs in this group are assigned the same semantics, but vary in
their elements and in valence selection.
\end{itemize}

Examples for the second group are given below:

\begin{itemize}
\item Multi-word adverbial constructions:

\verb+ + `on the other hand', \begin{otherlanguage*}{bulgarian}от
друга страна\end{otherlanguage*}, from other side

\verb+ + `of course',  \begin{otherlanguage*}{bulgarian}разбир-а
се\end{otherlanguage*}, understand-\textsc{PRS.3PL} \textsc{REFL}

\verb+ + `more and more', \begin{otherlanguage*}{bulgarian}все
повече и повече\end{otherlanguage*}, even more and more

\verb+ + `in particular',\begin{otherlanguage*}{bulgarian}в
частност\end{otherlanguage*}, in detail\\
Here, however, the prepositional complement varies in the PoS across the two languages. For example, in the last translational equivalent the English
prepositional complement  is the adjective \textit{particular}, while in Bulgarian it is the  noun \begin{otherlanguage*}{bulgarian}в
частност\end{otherlanguage*}.

The MWEs in this group are assigned the same semantics, but may vary in the
elements. However, this difference is not taken into consideration, because
the elements hardly inflect and do not
allow for the insertion of additional elements.

\item Complex prepositions in English tend to have structurally similar
counterparts in Bulgarian. For instance,

\verb+ + `with respect to', \begin{otherlanguage*}{bulgarian}що се
отнас-я до\end{otherlanguage*}, as far as relates-\textsc{PRS.3SG} to

The MWEs in this group are assigned the same semantics, but since, presumably, they are assigned the same PoS and do not inflect, the element variance is not relevant.

\item Conjunctions composed of multiple words:

\verb+ + `as well as',  \begin{otherlanguage*}{bulgarian}кактои\end{otherlanguage*}, as and
\end{itemize}
%\item

Like the complex preposition group, this group also contains MWEs that are
assigned the same semantics and the same PoS; these MWEs do not inflect,
therefore the element variance is not relevant.

%\end{itemize}

\subsection{ Cross-language specific types}

Here we include English phrasal verbs having Bulgarian reflexive se-verbs as translational equivalents and English nominal compounds having Bulgarian \linebreak Other NP
MWEs, mainly Adjective-Noun or Noun-Preposition-Noun, as translational
equivalents.
In this group, translational equivalents are assigned the same semantics,
but they may present systematic structural differences due to language
specific constructions. The elements in the MWEs always differ across
languages.

\begin{itemize}

\item English phrasal verbs often correspond to Bulgarian se-verbs:

\verb+ + `give up', \begin{otherlanguage*}{bulgarian}се
откаж-е\end{otherlanguage*}, \textsc{REFL} decline-\textsc{PRS.3SG}

\verb+ + `move back', \begin{otherlanguage*}{bulgarian}се
върн-ат\end{otherlanguage*}, \textsc{REFL} return-\textsc{PRS.3PL}

Bulgarian and English MWEs in this group may different in valency and in the
way meaning is constructed. Thus, Bulgarian uses the lexical aspect and the
reflexive се `se' to construct MWE meanings, while English uses the verb in
combination with the phrasal affix.

\item English N N compounds  can map to A N compounds in Bulgarian:

\verb+ + `face amount', \begin{otherlanguage*}{bulgarian}номинална
стойност\end{otherlanguage*}, nominal value

The MWEs in this group differ in the PoS of the modifier of the head noun:
with Bulgarian A N MWEs the head noun is modified by an adjective and with
English N N MWEs  by a noun.

\item English N N can also be translated as N PP in Bulgarian. The first
N in the English MWEs and the PP in the Bulgarian MWEs make the same
semantic contribution:

\verb+ + `law enforcement', \begin{otherlanguage*}{bulgarian}сил-и-те
на ред-а\end{otherlanguage*}, force-\textsc{PL-DEF} of order-\textsc{SG.DEF}

The MWEs in this group differ in the PoS of the modifier of the head noun:
with Bulgarian N NP MWEs the head noun is modified by a PP and with English
N N MWEs by a noun.

\item English N and N constructions  can apparently be translated with
coordinated constructions in Bulgarian; however, the PoS of the coordinated
constituents differs across the two languages:

\verb+ + `pros and cons', \begin{otherlanguage*}{bulgarian}доводи за
и против\end{otherlanguage*}, argument.\textsc{PL} for and against\\(N and N
/ N P and P)

The MWEs in this group differ in the head obligatoriness. In Bulgarian the
head noun is present, while in English a head noun is only inferred.

\item An English idiomatic clausal construction (V NP PP) can be translated
with a light verb construction in Bulgarian:

\verb+ + `putting pen to paper',
\begin{otherlanguage*}{bulgarian}предприел
действие\end{otherlanguage*}, take.\textsc{PTSP.3SG} action

The MWEs in this group differ with respect to modification and selectional
properties. The English MWE does not seem to admit any modifiers, while its
Bulgarian translational equivalent allows for them (for example,
\begin{otherlanguage*}{bulgarian}предприел важно
действие\end{otherlanguage*}, taken\textsc{PTSP.3SG}, important action

\item English V AP can be translated in Bulgarian with minimal
changes into V AdvP:

\verb+ + `broke even', \begin{otherlanguage*}{bulgarian}са излезли
начисто\end{otherlanguage*}, are come.out.\textsc{PRST.3SG} clean

The  English adjective \textit{even}  translates into the Bulgarian adverb
начисто `clean’.

\item English V PP  can be translated as V NP in Bulgarian:

\verb+ + `will be priced of a job', \begin{otherlanguage*}{bulgarian}ще
загубят работата си\end{otherlanguage*}, will
lose.\textsc{PRS.3PL} job \textsc{DEF}

It is interesting to observe that an English passive construction  can be
translated with a Bulgarian active construction. In such cases the
valency parts will differ with respect to both the predicate and the
participants.
\end{itemize}

%\end{itemize}

Our work on the Bulgarian-English lexicon aims to provide representations
for all these types of correspondence: the representations will be bilingual
catena-based lexical entries.


\section{Conclusions}
\label{Sec:Conclusions}

The paper has argued that the catena approach can be extended to model pairs
of translational equivalents retrieved from parallel English-Bulgarian
corpora with at least one MWE as a member. In this way,
cross-language asymmetries are handled.
Our frequency counts have shown that the {\em MWE-to-MWE} and {\em
MWE-to-word} correspondences are prevalent. In contrast, the {\em
MWE-to-phrase} correspondence was not found to have a wide distribution. It
would be interesting to perform a detailed analysis of more examples in
order to uncover persistent correspondences between the two languages. Such
knowledge can be used in designing automatic translation systems and in
identifying best practices in human translation. Furthermore, these
correspondences can possibly illuminate the different ways employed by the
two languages to express meaning.

The proposed catena model takes into consideration both flexibility and
idiomaticity when representing MWEs and words in the lexicon. These
dimensions can be detailed further depending on the available specific
subclassifications in a cross-lingual aspect.


\section*{Acknowledgments}

This research has received support by the EC's FP7 (FP7/2007-2013) under
grant agreement number 610516: ``QTLeap: Quality Translation by Deep
Language Engineering Approaches'' and by European COST Action IC1207:
``PARSEME: PARSing and Multi-word Expressions. Towards linguistic precision
and computational efficiency in natural language processing.''


\section*{Abbreviations}

\begin{table}
\begin{tabular}{ll}
\lsptoprule
Full form  & Abbreviation \\
\midrule
definite noun & def \\
Lexicon Catena & LC \\
part of speech & PoS \\
plural number & plur \\
possessive pronoun & poss \\
semantics & SM \\
valency frames & Fr \\
\lspbottomrule
\end{tabular}
\caption{Abbreviations.}
\end{table}


{\sloppy
\printbibliography[heading=subbibliography,notkeyword=this]
}

\end{document}

% \citet{Chomsky1957}
%\ea\label{ex:1:descartes}
%\langinfo{Latin}{}{personal knowledge}\\
%\gll cogit-o ergo sum \\
%     think-1{\sg}.{\prs}.{\ind} hence exist.1{\sg}.{\prs}.{\ind}\\
%\glt `I think therefore I am'
%\z

%\begin{table}
%\caption{Frequencies of word classes}
%\label{tab:1:frequencies}
% \begin{tabular}{lllll} % add l for every additional column or remove as
%necessary
%  \lsptoprule
%            & nouns & verbs & adjectives & adverbs\\ %table header
%  \midrule
%  absolute  &   12 &    34  &    23     & 13\\
%  relative  &   3.1 &   8.9 &    5.7    & 3.2\\
%  \lspbottomrule
% \end{tabular}
%\end{table}

% \isi{prolegomena}
